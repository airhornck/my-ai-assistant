from __future__ import annotations

import json
import logging
import time
from typing import Any, TypedDict

from langgraph.graph import END, StateGraph
from sqlalchemy import select

from database import AsyncSessionLocal, InteractionHistory, UserProfile
from models.request import ContentRequest
from services.ai_service import SimpleAIService
from workflows.evaluation_node import create_evaluation_node

logger = logging.getLogger(__name__)


class State(TypedDict):
    """
    å·¥ä½œæµçŠ¶æ€å®šä¹‰ - ä½¿ç”¨ TypedDict ç¡®ä¿ç±»å‹å®‰å…¨ã€‚
    """
    user_input: str
    analysis: str
    content: str
    session_id: str
    user_id: str
    evaluation: dict
    need_revision: bool
    stage_durations: dict  # å„é˜¶æ®µè€—æ—¶ï¼ˆç§’ï¼‰ï¼Œå¦‚ {"analyze": 0.5, "generate": 1.2, ...}
    analyze_cache_hit: bool  # åˆ†æé˜¶æ®µæ˜¯å¦å‘½ä¸­ç¼“å­˜
    used_tags: list  # æœ¬æ¬¡å®é™…ä¼ ç»™æ¨¡å‹çš„æ ‡ç­¾ï¼ˆè¯·æ±‚è¾“å…¥è¦†ç›–æˆ–ç³»ç»Ÿå†å²ç”Ÿæˆï¼Œä¾›å“åº”è¿”å›ï¼‰


def _build_preference_context(
    profile: UserProfile | None, histories: list, tags_override: list | None = None
) -> str:
    """
    ä» UserProfile ä¸æœ€è¿‘ InteractionHistory æ„å»º preference_context æ–‡æœ¬ã€‚
    tags_overrideï¼šè‹¥æä¾›åˆ™ç”¨å…¶ä½œä¸ºå…´è¶£æ ‡ç­¾ï¼ˆè¯·æ±‚è¾“å…¥è¦†ç›–ï¼‰ï¼›å¦åˆ™ç”¨ profile.tagsï¼ˆç³»ç»Ÿå†å²ç”Ÿæˆï¼‰ã€‚
    """
    parts = []
    if profile:
        if profile.preferred_style:
            parts.append(f"åå¥½é£æ ¼ï¼š{profile.preferred_style}")
        if profile.industry:
            parts.append(f"è¡Œä¸šï¼š{profile.industry}")
        if profile.brand_name:
            parts.append(f"å“ç‰Œï¼š{profile.brand_name}")
        # å…´è¶£æ ‡ç­¾ï¼šè¯·æ±‚è¾“å…¥è¦†ç›– > ç³»ç»Ÿæ ¹æ®å†å²ç”Ÿæˆçš„ profile.tags
        tags_to_show = tags_override if (tags_override is not None and len(tags_override) > 0) else (profile.tags if profile.tags and isinstance(profile.tags, list) else [])
        if tags_to_show:
            tags_str = "ã€".join(str(t) for t in tags_to_show)
            parts.append(f"å…´è¶£æ ‡ç­¾ï¼š{tags_str}")
    if parts:
        parts.insert(0, "ã€ç”¨æˆ·ç”»åƒã€‘")
        parts.append("")

    if histories:
        parts.append("ã€è¿‘æœŸäº¤äº’æ‘˜è¦ã€‘")
        for i, h in enumerate(histories, 1):
            topic = ""
            if h.user_input:
                try:
                    data = json.loads(h.user_input)
                    topic = (data.get("topic") or "") if isinstance(data, dict) else ""
                except (json.JSONDecodeError, TypeError):
                    pass
            summary = (h.ai_output or "")[:120].strip()
            if summary and len((h.ai_output or "")) > 120:
                summary += "â€¦"
            line = f"  {i}. ä¸»é¢˜ï¼š{topic or 'â€”'}"
            if summary:
                line += f"ï¼›è¾“å‡ºæ‘˜è¦ï¼š{summary}"
            parts.append(line)
        parts.append("")

    return "\n".join(parts).strip() if parts else ""


def _build_context_fingerprint(
    profile: UserProfile | None, histories: list, tags_override: list | None = None
) -> dict:
    """
    æ„å»ºç”¨äºåˆ†æç¼“å­˜çš„ä¸Šä¸‹æ–‡æŒ‡çº¹ï¼šç”¨æˆ·é•¿æœŸæ ‡ç­¾ï¼ˆå‚ä¸ç¼“å­˜é”®ï¼‰+ è¿‘ä¸‰æ¬¡äº¤äº’ä¸»é¢˜ï¼ˆä¾›æ‰©å±•ï¼‰ã€‚
    tags_overrideï¼šè‹¥æä¾›åˆ™ç”¨å…¶ä½œä¸ºç¼“å­˜é”®ä¸­çš„ tagsï¼›å¦åˆ™ç”¨ profile.tagsã€‚
    """
    if tags_override is not None and len(tags_override) > 0:
        tags_sorted = sorted(str(t) for t in tags_override)
    else:
        tags_sorted = []
        if profile and getattr(profile, "tags", None) and isinstance(profile.tags, list):
            tags_sorted = sorted(str(t) for t in profile.tags)
    recent_topics = []
    for h in histories[:3]:
        topic = ""
        if getattr(h, "user_input", None):
            try:
                data = json.loads(h.user_input) if isinstance(h.user_input, str) else {}
                topic = (data.get("topic") or "").strip() if isinstance(data, dict) else ""
            except (json.JSONDecodeError, TypeError):
                pass
        if topic:
            recent_topics.append(topic)
    # å»é‡å¹¶æ’åºï¼Œä½¿ (A,B,A) ä¸ (A,B) åœ¨é›†åˆä¸Šä¸€è‡´ï¼Œä¾¿äºå‘½ä¸­
    recent_topics_sorted = sorted(set(recent_topics))
    return {"tags": tags_sorted, "recent_topics": recent_topics_sorted}


def create_workflow(ai_service: SimpleAIService | None = None) -> Any:
    """
    åˆ›å»ºå·¥ä½œæµå›¾ã€‚å¯æ³¨å…¥ ai_serviceï¼ˆå¦‚å¸¦ç¼“å­˜çš„å®ä¾‹ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨æ–°å»ºçš„ SimpleAIService()ã€‚
    èŠ‚ç‚¹ä¼šè®°å½•å„é˜¶æ®µè€—æ—¶ï¼ˆstage_durationsï¼‰åŠåˆ†æé˜¶æ®µæ˜¯å¦å‘½ä¸­ç¼“å­˜ï¼ˆanalyze_cache_hitï¼‰ã€‚
    """
    ai_svc = ai_service or SimpleAIService()

    async def _analyze_node(state: State) -> State:
        t0 = time.perf_counter()
        user_id = state.get("user_id") or ""
        try:
            data = json.loads(state["user_input"])
            request = ContentRequest(**data)
        except (json.JSONDecodeError, TypeError):
            request = ContentRequest(
                user_id=user_id,
                brand_name="",
                product_desc=state.get("user_input", ""),
                topic="",
            )
        preference_context = ""
        context_fingerprint = {"tags": [], "recent_topics": []}
        # å…ˆæŒ‰è¯·æ±‚è¾“å…¥ç¡®å®š effective_tagsï¼Œä¿è¯ç¼“å­˜é”®ä¸è¯·æ±‚ä¸€è‡´ï¼ˆå³ä½¿ DB å¼‚å¸¸ä¹Ÿèƒ½å‘½ä¸­ï¼‰
        if getattr(request, "tags", None) and len(request.tags) > 0:
            effective_tags = list(request.tags)
        else:
            effective_tags = []
        async with AsyncSessionLocal() as session:
            try:
                rp = await session.execute(select(UserProfile).where(UserProfile.user_id == user_id))
                profile = rp.scalar_one_or_none()
                rh = await session.execute(
                    select(InteractionHistory)
                    .where(InteractionHistory.user_id == user_id)
                    .order_by(InteractionHistory.created_at.desc())
                    .limit(3)
                )
                histories = rh.scalars().all()
                # æ— è¯·æ±‚ tags æ—¶å†ç”¨ç³»ç»Ÿæ ¹æ®å†å²ç”Ÿæˆçš„ profile.tags
                if not effective_tags and profile and getattr(profile, "tags", None) and isinstance(profile.tags, list):
                    effective_tags = list(profile.tags)
                preference_context = _build_preference_context(profile, histories, tags_override=effective_tags)
                context_fingerprint = _build_context_fingerprint(profile, histories, tags_override=effective_tags)
            except Exception as e:
                logger.warning("analyze_node æŸ¥è¯¢é•¿æœŸè®°å¿†å¤±è´¥ï¼Œé™çº§ä¸ºç©ºä¸Šä¸‹æ–‡: %s", e, exc_info=True)
                # å¼‚å¸¸æ—¶ context_fingerprint ä»ç”¨ä¸Šé¢å·²ç®—å¥½çš„ effective_tagsï¼Œä¿è¯ç¼“å­˜é”®ä¸€è‡´
                context_fingerprint = {"tags": sorted(str(t) for t in effective_tags), "recent_topics": []}
        analysis_result, cache_hit = await ai_svc.analyze(
            request,
            preference_context=preference_context or None,
            context_fingerprint=context_fingerprint,
        )
        duration = round(time.perf_counter() - t0, 4)
        return {
            **state,
            "analysis": analysis_result,
            "evaluation": state.get("evaluation", {}),
            "need_revision": state.get("need_revision", False),
            "stage_durations": {**state.get("stage_durations", {}), "analyze": duration},
            "analyze_cache_hit": cache_hit,
            "used_tags": effective_tags,
        }

    async def _generate_node(state: State) -> State:
        t0 = time.perf_counter()
        generated_content = await ai_svc.generate(state["analysis"])
        duration = round(time.perf_counter() - t0, 4)
        return {
            **state,
            "content": generated_content,
            "evaluation": state.get("evaluation", {}),
            "need_revision": state.get("need_revision", False),
            "stage_durations": {**state.get("stage_durations", {}), "generate": duration},
            "analyze_cache_hit": state.get("analyze_cache_hit", False),
            "used_tags": state.get("used_tags", []),
        }

    def _format_node(state: State) -> State:
        t0 = time.perf_counter()
        analysis = state.get("analysis")
        if isinstance(analysis, dict):
            analysis_display = (
                f"å¾—åˆ† {analysis.get('semantic_score', 0)}ï¼›"
                f"åˆ‡å…¥ç‚¹ï¼š{analysis.get('angle', '')}ï¼›ç†ç”±ï¼š{analysis.get('reason', '')}"
            )
        else:
            analysis_display = analysis if isinstance(analysis, str) else ""
        formatted_content = f"ğŸ“ æ¨å¹¿æ–‡æ¡ˆï¼š\n\n{state['content']}\n\nâœ¨ åŸºäºåˆ†æï¼š{analysis_display}"
        duration = round(time.perf_counter() - t0, 4)
        return {
            **state,
            "content": formatted_content,
            "evaluation": state.get("evaluation", {}),
            "need_revision": state.get("need_revision", False),
            "stage_durations": {**state.get("stage_durations", {}), "format": duration},
            "analyze_cache_hit": state.get("analyze_cache_hit", False),
            "used_tags": state.get("used_tags", []),
        }

    workflow = StateGraph(State)
    workflow.add_node("analyze", _analyze_node)
    workflow.add_node("generate", _generate_node)
    workflow.add_node("format", _format_node)
    workflow.add_node("evaluate", create_evaluation_node(ai_svc))
    workflow.set_entry_point("analyze")
    workflow.add_edge("analyze", "generate")
    workflow.add_edge("generate", "format")
    workflow.add_edge("format", "evaluate")
    workflow.add_edge("evaluate", END)
    return workflow.compile()